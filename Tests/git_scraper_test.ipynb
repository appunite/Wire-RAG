{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T12:54:27.554363Z",
     "start_time": "2024-09-26T12:53:53.956217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import aiohttp\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Required to handle async calls within Jupyter or other event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "async def fetch_repositories(session: aiohttp.ClientSession, org_name: str, api_key: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Returns a list of repositories in the given organization.\n",
    "    Each repository is represented as a dictionary with repository metadata.\n",
    "    \"\"\"\n",
    "    all_repos = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f\"https://api.github.com/orgs/{org_name}/repos\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"token {api_key}\",\n",
    "            \"Accept\": \"application/vnd.github.v3+json\"\n",
    "        }\n",
    "        params = {\n",
    "            \"per_page\": 100,  # Maximum of 100 items per page\n",
    "            \"page\": page\n",
    "        }\n",
    "\n",
    "        async with session.get(url, headers=headers, params=params) as response:\n",
    "            if response.status == 200:\n",
    "                repos = await response.json()\n",
    "                if not repos:\n",
    "                    break  # Stop when no more repositories are found\n",
    "                all_repos.extend(repos)\n",
    "                page += 1  # Move to the next page for pagination\n",
    "            else:\n",
    "                print(f\"Error fetching repositories for {org_name}: {response.status}\")\n",
    "                break\n",
    "    return all_repos\n",
    "\n",
    "async def fetch_repo_contents(session: aiohttp.ClientSession, repo_full_name: str, api_key, path=\"\") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Returns the contents of a given repository, which can include files and directories.\n",
    "    The contents are represented as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/{repo_full_name}/contents/{path}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {api_key}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    async with session.get(url, headers=headers) as response:\n",
    "        if response.status == 200:\n",
    "            return await response.json()\n",
    "        else:\n",
    "            print(f\"Error fetching contents for {repo_full_name}/{path}: {response.status}\")\n",
    "            return []\n",
    "\n",
    "async def fetch_md_files(session: aiohttp.ClientSession, repo_full_name: str, api_key, path=\"\") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Recursively fetches all Markdown (.md) files from the repository and directories.\n",
    "    Returns a list of dictionaries with the file name, download URL, and other metadata.\n",
    "    \"\"\"\n",
    "    contents = await fetch_repo_contents(session, repo_full_name, api_key, path)\n",
    "    md_files = []\n",
    "\n",
    "    for item in contents:\n",
    "        if item['type'] == 'file' and item['name'].endswith('.md'):\n",
    "            # Fetch .md file along with its download URL and other metadata\n",
    "            md_files.append({\n",
    "                'repo_full_name': repo_full_name,\n",
    "                'path': item['path'],\n",
    "                'self_url': item['url'],\n",
    "                'html_url': item['html_url'],\n",
    "                'git_url': item['git_url'],\n",
    "                'download_url': item['download_url'],\n",
    "                'last_modified': ''  # Placeholder for last modified date\n",
    "            })\n",
    "        elif item['type'] == 'dir':  # If it's a directory, recursively fetch contents\n",
    "            md_files += await fetch_md_files(session, repo_full_name, api_key, item['path'])\n",
    "\n",
    "    return md_files\n",
    "\n",
    "async def fetch_last_modified_date(session: aiohttp.ClientSession, repo_full_name: str, file_path: str, api_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the last commit date for a given file in the repository by checking its commit history.\n",
    "    Returns the date in ISO 8601 format (e.g., \"2023-09-26T12:34:56Z\").\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/{repo_full_name}/commits\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {api_key}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    params = {\n",
    "        \"path\": file_path,  # Specify the file path to get commits for this specific file\n",
    "        \"per_page\": 1,  # We only need the latest commit, so limit the result to 1\n",
    "    }\n",
    "\n",
    "    async with session.get(url, headers=headers, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            commits = await response.json()\n",
    "            if commits:\n",
    "                return commits[0]['commit']['committer']['date']  # Last commit date\n",
    "            else:\n",
    "                return \"Unknown\"  # If no commits found, return \"Unknown\"\n",
    "        else:\n",
    "            print(f\"Error fetching commit info for {repo_full_name}/{file_path}: {response.status}\")\n",
    "            return \"Unknown\"\n",
    "\n",
    "async def scrape_md_files(org_name: str, api_key) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Main function to scrape .md files from all repositories in the organization.\n",
    "    Returns a list of dictionaries containing the file name, download URL, and last updated date.\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        repos = await fetch_repositories(session, org_name, api_key)\n",
    "    \n",
    "        # Create async tasks for each repo to fetch .md files concurrently\n",
    "        tasks = [fetch_md_files(session, repo['full_name'], api_key) for repo in repos[:3]]\n",
    "        all_md_files = await asyncio.gather(*tasks)\n",
    "\n",
    "        # Flatten the list of lists into a single list\n",
    "        md_files = [md_file for repo_files in all_md_files for md_file in repo_files]\n",
    "        \n",
    "        for md_file in md_files:\n",
    "            md_file['last_modified'] = await fetch_last_modified_date(\n",
    "                session, \n",
    "                repo_full_name=md_file['repo_full_name'],\n",
    "                file_path=md_file['path'],\n",
    "                api_key=api_key\n",
    "            )\n",
    "        return md_files\n",
    "\n",
    "# Example usage\n",
    "md_files = await scrape_md_files(\"wireapp\", os.getenv(\"GITHUB_API_TOKEN\"))\n",
    "print(f\"Found {len(md_files)} Markdown files:\")\n",
    "for file in md_files:\n",
    "    print(f\"Path: {file['path']}, URL: {file['download_url']}, Last Modified: {file['last_modified']}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 Markdown files:\n",
      "Path: README.md, URL: https://raw.githubusercontent.com/wireapp/libsodium.js/master/README.md, Last Modified: 2015-10-07T14:36:01Z\n",
      "Path: .github/ISSUE_TEMPLATE/bugs.md, URL: https://raw.githubusercontent.com/wireapp/libsodium/master/.github/ISSUE_TEMPLATE/bugs.md, Last Modified: 2021-11-12T21:57:25Z\n",
      "Path: README.md, URL: https://raw.githubusercontent.com/wireapp/cryptobox-haskell/master/README.md, Last Modified: 2016-07-21T12:38:21Z\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.6 (haystack)",
   "language": "python",
   "name": "haystack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
